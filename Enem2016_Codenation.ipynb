{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Enem_2016",
      "provenance": [],
      "authorship_tag": "ABX9TyMget2k63hAaTBYD3IAqjEW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Romulo-Anjos/Codenation_2020/blob/master/Enem2016_Codenation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6R9I6g5Zjv-F",
        "colab_type": "text"
      },
      "source": [
        "Starting by importing the libraries and data provided for the exercise"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5IYr4ZatiiAa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Importing Libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "# Import the dataset\n",
        "raw_test =  pd.read_csv('test.csv')\n",
        "raw_train = pd.read_csv('train.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vhRwKf8ja7u",
        "colab_type": "text"
      },
      "source": [
        "Taking a look on the dimensions on both files:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fciiEBNjlIH",
        "colab_type": "code",
        "outputId": "6ee1eb42-d967-414b-fc87-ccf7c5893df9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "print(raw_train.shape)\n",
        "print(raw_test.shape)"
      ],
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(13730, 167)\n",
            "(4576, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ogyAB93k5EfK",
        "colab_type": "text"
      },
      "source": [
        "# **1 - Data Preprocessing**\n",
        "\n",
        "**A) Eliminating the empty data**\n",
        "\n",
        "Checking for the Null values for the grades on the Train data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB4_6-HmZTss",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        },
        "outputId": "8a9f743f-be9b-446e-847e-d09f8eb17270"
      },
      "source": [
        "#Missing Data on Merge Dataset\n",
        "print('Missing Data on NU_NOTA_MT:',raw_train['NU_NOTA_MT'].isnull().sum())\n",
        "print('Missing Data on NU_NOTA_CN:',raw_train['NU_NOTA_CN'].isnull().sum())\n",
        "print('Missing Data on NU_NOTA_CH:',raw_train['NU_NOTA_CH'].isnull().sum())\n",
        "print('Missing Data on NU_NOTA_REDACAO:',raw_train['NU_NOTA_REDACAO'].isnull().sum())\n",
        "print('Missing Data on NU_NOTA_LC:',raw_train['NU_NOTA_LC'].isnull().sum())"
      ],
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Missing Data on NU_NOTA_MT: 3597\n",
            "Missing Data on NU_NOTA_CN: 3389\n",
            "Missing Data on NU_NOTA_CH: 3389\n",
            "Missing Data on NU_NOTA_REDACAO: 3597\n",
            "ERROR! Session/line number was not unique inMissing Data on NU_NOTA_LC: 3597 \n",
            "database. History logging moved to new session 61\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EBifXuC5cYyW",
        "colab_type": "text"
      },
      "source": [
        "Once the grades for Math, Writing and Languages are the same, it is possible to infer that the three tests were given at the same date. So, the null values refer to students that didn't take the test. Therefore is necessary to take off this Id's from the both datasets because there is no need to predict the Math grade (it is already 0)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EztRj18n4L8M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ID = 'NU_INSCRICAO'\n",
        "# Store ID's of Test Dataset which we will set the prediction result as NaN\n",
        "NaNs_ID = raw_test.loc[raw_test['TP_STATUS_REDACAO'].isnull(),ID] # Saving the NaN IDs that will be added on the answer file after the prediction\n",
        "raw_test = raw_test[~raw_test['TP_STATUS_REDACAO'].isnull()] #Remove those examples from test dataset\n",
        "raw_train = raw_train[~raw_train['TP_STATUS_REDACAO'].isnull()] #Remove those examples from train dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6V0SxOtdZY8",
        "colab_type": "text"
      },
      "source": [
        "Checking the new dimension for the Train and Test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tqdgywEB61Bl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d8e37ddb-376e-4a74-e035-b2ba099b80d4"
      },
      "source": [
        "print(raw_train.shape)\n",
        "print(raw_test.shape)"
      ],
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(10133, 167)\n",
            "(3377, 47)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m03N6K3Gj5l-",
        "colab_type": "text"
      },
      "source": [
        "**B) Choosing the most important variables**\n",
        "\n",
        "I analised the dictionary for the columns provided on the files. After analising the Dictionary of columns, I selected the most important columns to be analyzed:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDBPEKMOkLNE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_train= raw_train[[#'NU_INSCRICAO',\n",
        "'TP_SEXO',\n",
        "'Q006',\n",
        "'NU_NOTA_CN',\n",
        "'NU_NOTA_CH',\n",
        "'NU_NOTA_LC',\n",
        "'NU_NOTA_MT']]\n",
        "data_test= raw_test[[#'NU_INSCRICAO',\n",
        "'TP_SEXO',\n",
        "'Q006',\n",
        "'NU_NOTA_CN',\n",
        "'NU_NOTA_CH',\n",
        "'NU_NOTA_LC',\n",
        "]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzKM8Uf5e8GX",
        "colab_type": "text"
      },
      "source": [
        "**C) Treating the missing data**\n",
        "\n",
        "I will check what data I still need to treat (NaN values)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NBZih9VaeaGr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e4650ebf-6675-4d6b-c1c2-e09fb72bffc5"
      },
      "source": [
        "# Missing Data on Train Dataset\n",
        "total = data_train.isnull().sum().sort_values(ascending=False)\n",
        "percent = (data_train.isnull().sum()/data_train.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "\n",
        "# Missing Data on Test Dataset\n",
        "total = data_test.isnull().sum().sort_values(ascending=False)\n",
        "percent = (data_test.isnull().sum()/data_test.isnull().count()).sort_values(ascending=False)\n",
        "missing_data_test = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "\n",
        "\n",
        "print (missing_data.head(20))\n",
        "print (missing_data_test.head(20))"
      ],
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Total   Percent\n",
            "NU_NOTA_CH     36  0.003553\n",
            "NU_NOTA_CN     36  0.003553\n",
            "NU_NOTA_MT      0  0.000000\n",
            "NU_NOTA_LC      0  0.000000\n",
            "Q006            0  0.000000\n",
            "TP_SEXO         0  0.000000\n",
            "            Total   Percent\n",
            "NU_NOTA_CH     17  0.005034\n",
            "NU_NOTA_CN     17  0.005034\n",
            "NU_NOTA_LC      0  0.000000\n",
            "Q006            0  0.000000\n",
            "TP_SEXO         0  0.000000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZdOf2re7mUk",
        "colab_type": "text"
      },
      "source": [
        "Completing the missed data with the mean values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUPRw9KNucVn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Taking care of missing data (grades)\n",
        "from sklearn.impute import SimpleImputer\n",
        "missingvalues = SimpleImputer(missing_values=np.nan, strategy='mean', verbose=0)\n",
        "missingvalues = missingvalues.fit(data_train.iloc[:,2:6])\n",
        "data_train.iloc[:,2:6]=missingvalues.transform(data_train.iloc[:,2:6])\n",
        "\n",
        "# Taking care of missing data (grades)\n",
        "from sklearn.impute import SimpleImputer\n",
        "missingvalues = SimpleImputer(missing_values=np.nan, strategy='mean', verbose=0)\n",
        "missingvalues = missingvalues.fit(data_test.iloc[:,2:5])\n",
        "data_test.iloc[:,2:5]=missingvalues.transform(data_test.iloc[:,2:5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMkLyBq7gBKN",
        "colab_type": "text"
      },
      "source": [
        "Checking now the number of NaN values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKga8crJ47-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "c46a4fa8-591c-492d-e2a3-ed29177a0580"
      },
      "source": [
        "# Missing Data on Train Dataset\n",
        "total = data_train.isnull().sum().sort_values(ascending=False)\n",
        "percent = (data_train.isnull().sum()/data_train.isnull().count()).sort_values(ascending=False)\n",
        "missing_data = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "\n",
        "# Missing Data on Test Dataset\n",
        "total = data_test.isnull().sum().sort_values(ascending=False)\n",
        "percent = (data_test.isnull().sum()/data_test.isnull().count()).sort_values(ascending=False)\n",
        "missing_data_test = pd.concat([total, percent], axis=1, keys=['Total', 'Percent'])\n",
        "\n",
        "\n",
        "print (missing_data.head(20))\n",
        "print (missing_data_test.head(20))"
      ],
      "execution_count": 190,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "            Total  Percent\n",
            "NU_NOTA_MT      0      0.0\n",
            "NU_NOTA_LC      0      0.0\n",
            "NU_NOTA_CH      0      0.0\n",
            "NU_NOTA_CN      0      0.0\n",
            "Q006            0      0.0\n",
            "TP_SEXO         0      0.0\n",
            "            Total  Percent\n",
            "NU_NOTA_LC      0      0.0\n",
            "NU_NOTA_CH      0      0.0\n",
            "NU_NOTA_CN      0      0.0\n",
            "Q006            0      0.0\n",
            "TP_SEXO         0      0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hAyQHbD5Vy2",
        "colab_type": "text"
      },
      "source": [
        "**D) Encoding the variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sJtjBhP85UsK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        },
        "outputId": "63678737-a2a0-4931-dfac-a0dee06266c9"
      },
      "source": [
        "qualitative_features_test = [q for q in data_test.columns \n",
        "                        if (data_test[q].dtypes == object) | (data_test[q].dtypes == bool)] #List of Features Qualitativas from test dataset\n",
        "\n",
        "qualitative_features_train = [q for q in data_train.columns \n",
        "                        if (data_train[q].dtypes == object) | (data_train[q].dtypes == bool)] #List of Features Qualitativas from train dataset\n",
        "\n",
        "from collections import defaultdict\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "d = defaultdict(LabelEncoder)\n",
        "### Encoding the variables from data_test\n",
        "fit = data_test[qualitative_features_test].apply(lambda x_test: d[x_test.name].fit_transform(x_test))\n",
        "data_test[qualitative_features_test] = fit\n",
        "\n",
        "### Encoding the variables from data_train\n",
        "fit = data_train[qualitative_features_train].apply(lambda x_train: d[x_train.name].fit_transform(x_train))\n",
        "data_train[qualitative_features_train] = fit"
      ],
      "execution_count": 191,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pandas/core/frame.py:3509: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  self[k1] = value[k2]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcUwX7rw5Qsa",
        "colab_type": "text"
      },
      "source": [
        "# **2 - Building the Model**\n",
        "\n",
        "Defining X and y for data_train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxmCyDCvxJmn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defining the X and y for data_train\n",
        "X = data_train.iloc[:,:-1].values\n",
        "y = data_train.iloc[:,5].values\n",
        "\n",
        "# Splitting the dataset into the Training set and Test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZiZoIB-ALjR",
        "colab_type": "text"
      },
      "source": [
        "Executing the Linear Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwAWL8eG9NsV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting Multiple Linear Regression in the Training Set\n",
        "from sklearn.linear_model import LinearRegression\n",
        "regressor =  LinearRegression()\n",
        "regressor.fit(X_train, y_train)\n",
        "\n",
        "# Predicting the Test set results\n",
        "y_pred = regressor.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SaXUWltmAOeK",
        "colab_type": "text"
      },
      "source": [
        "Optimizing the optimal model using Backward Elimination"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WXoZi-WEhKpg",
        "colab": {}
      },
      "source": [
        "# Building the optimal model using Backward Elimination\n",
        "import statsmodels.api as sm\n",
        "X = np.append(arr = np.ones((10133,1)).astype(int), values = X, axis = 1)\n",
        "X_opt = X[:,[0,1,2,3,4]]\n",
        "regressor_OLS = sm.OLS(endog = y, exog= X_opt).fit()\n",
        "regressor_OLS.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QBabI7MWhmhJ",
        "colab_type": "text"
      },
      "source": [
        "Creating the predictions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L6ujrT1Rskp-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction = regressor.predict(data_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8sR4_8Yhqh-",
        "colab_type": "text"
      },
      "source": [
        "Creating the file to be submitted at Codenation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DQc8wiB_2GGy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_saida = pd.DataFrame(\n",
        "        {'NU_INSCRICAO':list(test_id)+list(NaNs_ID), #Including the IDs of empty values I took off to build the model\n",
        "         'NU_NOTA_MT':list(prediction)+[np.nan]*len(NaNs_ID) # The same as the line before\n",
        "                })\n",
        "df_saida.to_csv(r'/content/sample_data/answer_3.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XvGB_YMk6fQ",
        "colab_type": "text"
      },
      "source": [
        "Executing the Random Forest\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N78HTifvk512",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Fitting Random Forest Regression to the dataset\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "regressor = RandomForestRegressor(n_estimators = 100, random_state = 0)\n",
        "regressor.fit(X_train,y_train)\n",
        "\n",
        "# Predicting a new result\n",
        "y_pred_random = regressor.predict(X_test)\n",
        "\n",
        "prediction_2 = regressor.predict(data_test)\n",
        "\n",
        "df_saida = pd.DataFrame(\n",
        "        {'NU_INSCRICAO':list(test_id)+list(NaNs_ID), #Including the IDs of empty values I took off to build the model\n",
        "         'NU_NOTA_MT':list(prediction_2)+[np.nan]*len(NaNs_ID) # The same as the line before\n",
        "                })\n",
        "df_saida.to_csv(r'/content/sample_data/answer_random.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}